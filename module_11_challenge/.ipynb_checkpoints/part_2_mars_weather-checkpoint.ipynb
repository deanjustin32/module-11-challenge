{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 Challenge\n",
    "## Deliverable 2: Scrape and Analyze Mars Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Visit the Website\n",
    "\n",
    "Use automated browsing to visit the [Mars Temperature Data Site](https://static.bc-edx.com/data/web/mars_facts/temperature.html). Inspect the page to identify which elements to scrape.\n",
    "\n",
    "   > **Hint** To identify which elements to scrape, you might want to inspect the page by using Chrome DevTools to discover whether the table contains usable classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the website\n",
    "# https://static.bc-edx.com/data/web/mars_facts/temperature.html\n",
    "url=\"https://static.bc-edx.com/data/web/mars_facts/temperature.html\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the Table\n",
    "\n",
    "Create a Beautiful Soup object and use it to scrape the data in the HTML table.\n",
    "\n",
    "Note that this can also be achieved by using the Pandas `read_html` function. However, use Beautiful Soup here to continue sharpening your web scraping skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Beautiful Soup Object\n",
    "html = browser.html\n",
    "soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>terrestrial_date</th>\n",
       "      <th>sol</th>\n",
       "      <th>ls</th>\n",
       "      <th>month</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-08-16</td>\n",
       "      <td>10</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>11</td>\n",
       "      <td>156</td>\n",
       "      <td>6</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>2012-08-18</td>\n",
       "      <td>12</td>\n",
       "      <td>156</td>\n",
       "      <td>6</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>741.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>2012-08-19</td>\n",
       "      <td>13</td>\n",
       "      <td>157</td>\n",
       "      <td>6</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>2012-08-20</td>\n",
       "      <td>14</td>\n",
       "      <td>157</td>\n",
       "      <td>6</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>1889</td>\n",
       "      <td>2018-02-23</td>\n",
       "      <td>1973</td>\n",
       "      <td>133</td>\n",
       "      <td>5</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>1892</td>\n",
       "      <td>2018-02-24</td>\n",
       "      <td>1974</td>\n",
       "      <td>134</td>\n",
       "      <td>5</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>1894</td>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>1975</td>\n",
       "      <td>134</td>\n",
       "      <td>5</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>1893</td>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>1976</td>\n",
       "      <td>135</td>\n",
       "      <td>5</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>1895</td>\n",
       "      <td>2018-02-27</td>\n",
       "      <td>1977</td>\n",
       "      <td>135</td>\n",
       "      <td>5</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>727.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id terrestrial_date   sol   ls  month  min_temp  pressure\n",
       "0        2       2012-08-16    10  155      6     -75.0     739.0\n",
       "1       13       2012-08-17    11  156      6     -76.0     740.0\n",
       "2       24       2012-08-18    12  156      6     -76.0     741.0\n",
       "3       35       2012-08-19    13  157      6     -74.0     732.0\n",
       "4       46       2012-08-20    14  157      6     -74.0     740.0\n",
       "...    ...              ...   ...  ...    ...       ...       ...\n",
       "1862  1889       2018-02-23  1973  133      5     -78.0     730.0\n",
       "1863  1892       2018-02-24  1974  134      5     -77.0     729.0\n",
       "1864  1894       2018-02-25  1975  134      5     -76.0     729.0\n",
       "1865  1893       2018-02-26  1976  135      5     -77.0     728.0\n",
       "1866  1895       2018-02-27  1977  135      5     -77.0     727.0\n",
       "\n",
       "[1867 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all rows of data\n",
    "data_table = soup.find_all('table')\n",
    "data_df = pd.read_html(str(data_table))[0]\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Store the Data\n",
    "\n",
    "Assemble the scraped data into a Pandas DataFrame. The columns should have the same headings as the table on the website. Here’s an explanation of the column headings:\n",
    "\n",
    "* `id`: the identification number of a single transmission from the Curiosity rover\n",
    "* `terrestrial_date`: the date on Earth\n",
    "* `sol`: the number of elapsed sols (Martian days) since Curiosity landed on Mars\n",
    "* `ls`: the solar longitude\n",
    "* `month`: the Martian month\n",
    "* `min_temp`: the minimum temperature, in Celsius, of a single Martian day (sol)\n",
    "* `pressure`: The atmospheric pressure at Curiosity's location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19068\\2957328082.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Loop through the scraped data to create a list of rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmars_weather_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'th'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mheader_element\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmars_weather_table\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'table' is not defined"
     ]
    }
   ],
   "source": [
    "# Create an empty list\n",
    "mars_weather = []\n",
    "\n",
    "# Loop through the scraped data to create a list of rows\n",
    "mars_weather_table = table.find_all('th')\n",
    "\n",
    "for header_element in mars_weather_table:\n",
    "    title = header_element.text\n",
    "    mars_weather.append(title)\n",
    "mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame by using the list of rows and a list of the column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm DataFrame was created successfully\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Prepare Data for Analysis\n",
    "\n",
    "Examine the data types that are currently associated with each column. If necessary, cast (or convert) the data to the appropriate `datetime`, `int`, or `float` data types.\n",
    "\n",
    "  > **Hint** You can use the Pandas `astype` and `to_datetime` methods to accomplish this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine data type of each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types for data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm type changes were successful by examining data types again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Analyze the Data\n",
    "\n",
    "Analyze your dataset by using Pandas functions to answer the following questions:\n",
    "\n",
    "1. How many months exist on Mars?\n",
    "2. How many Martian (and not Earth) days worth of data exist in the scraped dataset?\n",
    "3. What are the coldest and the warmest months on Mars (at the location of Curiosity)? To answer this question:\n",
    "    * Find the average the minimum daily temperature for all of the months.\n",
    "    * Plot the results as a bar chart.\n",
    "4. Which months have the lowest and the highest atmospheric pressure on Mars? To answer this question:\n",
    "    * Find the average the daily atmospheric pressure of all the months.\n",
    "    * Plot the results as a bar chart.\n",
    "5. About how many terrestrial (Earth) days exist in a Martian year? To answer this question:\n",
    "    * Consider how many days elapse on Earth in the time that Mars circles the Sun once.\n",
    "    * Visually estimate the result by plotting the daily minimum temperature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. How many months are there on Mars?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. How many Martian days' worth of data are there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. What is the average low temperature by month?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average temperature by month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the coldest and hottest months in Curiosity's location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Average pressure by Martian month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average pressure by month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. How many terrestrial (earth) days are there in a Martian year?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, the third month has the coldest minimum temperature on Mars, and the eighth month is the warmest. But it is always very cold there in human terms!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atmospheric pressure is, on average, lowest in the sixth month and highest in the ninth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance from peak to peak is roughly 1425-750, or 675 days. A year on Mars appears to be about 675 days from the plot. Internet search confirms that a Mars year is equivalent to 687 earth days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Save the Data\n",
    "\n",
    "Export the DataFrame to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to a CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
